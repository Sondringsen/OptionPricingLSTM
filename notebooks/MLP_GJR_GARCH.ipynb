{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RcTGoUnAo_sG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from pathlib import Path\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "HwI8mUIUwzO6"
      },
      "outputs": [],
      "source": [
        "#Variables\n",
        "first_year = 2019\n",
        "last_year = 2021\n",
        "split_date =\"2021-01-01\"\n",
        "\n",
        "epochs = 100\n",
        "\n",
        "features = [\"Underlying_last\", \"Strike\", \"Ttl\", \"Volatility_GJR_GARCH\", \"R\"]\n",
        "num_features = len(features)\n",
        "num_outputs = 1\n",
        "seq_length = 5\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "cd-EqCZ_1Bok"
      },
      "outputs": [],
      "source": [
        "def read_file(file):\n",
        "    \"\"\"Read a single file and return a dataframe\"\"\"\n",
        "    return pd.read_csv(file, skipinitialspace=True)\n",
        "\n",
        "def lag_features(df, features, seq_length):\n",
        "    \"\"\"Transforms a raw 2D dataframe of option data into 2D dataframe ofsequence data.\n",
        "    Last 2 indexes per sequence are bid and ask price. The len(features)*seq_length\n",
        "    features before are sequences of features\"\"\"\n",
        "    df = df.sort_values([\"Expire_date\", \"Strike\", \"Ttl\"], ascending = [True, True, False])\n",
        "\n",
        "    for step in range(seq_length)[::-1]:\n",
        "        for feature in features:\n",
        "            df[feature + \"-\" + str(step)] = df[feature].shift(step)\n",
        "    \n",
        "    df[\"Check_strike\"] = df[\"Strike\"] == df[\"Strike\"].shift(seq_length-1)\n",
        "    df[\"Check_expire\"] = df[\"Expire_date\"] == df[\"Expire_date\"].shift(seq_length-1)\n",
        "    df = df[(df[\"Check_strike\"] == True) & (df[\"Check_expire\"] == True)]\n",
        "    df = df.drop([\"Check_strike\", \"Check_expire\"], axis=1)\n",
        "    #df[[\"Bid_strike_last\", \"Ask_strike_last\"]] = df[[\"Bid_strike\", \"Ask_strike\"]]\n",
        "    #df[[\"Bid_last\", \"Ask_last\"]] = df[[\"Bid\", \"Ask\"]]\n",
        "    df[\"Price_last\"] = df[\"Price\"]\n",
        "    df = df.sort_values([\"Quote_date\"], ascending = [True])\n",
        "    return df\n",
        "\n",
        "def create_train_test(df, split_date):\n",
        "    \"\"\"Splits data in training and test set, and transforms data to right 2D format\"\"\"\n",
        "    return df[df[\"Quote_date\"] < split_date], df[df[\"Quote_date\"] >= split_date]\n",
        "\n",
        "def df_to_xy(df):\n",
        "    \"\"\"Transforms a dataframe into two arrays of explanatory variables x and explained variables y\"\"\"\n",
        "    dx = df[[\"Underlying_last\", \"Strike\", \"Ttl\", \"Volatility_GJR_GARCH\", \"R\"]]\n",
        "    dy = df[\"Price\"]\n",
        "    array_x, array_y = dx.to_numpy().astype(np.float32), dy.to_numpy().astype(np.float32)\n",
        "    return array_x, array_y\n",
        "\n",
        "def min_max_scale(train, test):\n",
        "    \"\"\"Scales a training and test set using MinMaxScaler. The scaler is calibrated on the training set\"\"\"\n",
        "    scaler = MinMaxScaler()\n",
        "    train = scaler.fit_transform(train)\n",
        "    test = scaler.transform(test)\n",
        "    return train, test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uUf4mmpspOVv",
        "outputId": "62b87b7a-6054-4a19-acdb-4a94b7ad1e7b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "         Unnamed: 0  Quote_date Expire_date     Price  Underlying_last  \\\n",
            "0           1354913  2019-01-02  2019-01-04  1707.050          2509.98   \n",
            "1           1354914  2019-01-02  2019-01-04  1607.495          2509.98   \n",
            "2           1354915  2019-01-02  2019-01-04  1507.500          2509.98   \n",
            "3           1354916  2019-01-02  2019-01-04  1458.295          2509.98   \n",
            "4           1354917  2019-01-02  2019-01-04  1408.300          2509.98   \n",
            "...             ...         ...         ...       ...              ...   \n",
            "5123793     6521988  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123794     6521989  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123795     6521990  2021-12-31  2024-12-20   150.900          4766.39   \n",
            "5123796     6521991  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123797     6521992  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "\n",
            "         Strike   Ttl  Volatility  Volatility_GJR_GARCH     R  \n",
            "0         800.0     2    0.202726              0.272634  2.40  \n",
            "1         900.0     2    0.202726              0.272634  2.40  \n",
            "2        1000.0     2    0.202726              0.272634  2.40  \n",
            "3        1050.0     2    0.202726              0.272634  2.40  \n",
            "4        1100.0     2    0.202726              0.272634  2.40  \n",
            "...         ...   ...         ...                   ...   ...  \n",
            "5123793  8400.0  1085    0.136456              0.118550  0.97  \n",
            "5123794  8600.0  1085    0.136456              0.118550  0.97  \n",
            "5123795  8800.0  1085    0.136456              0.118550  0.97  \n",
            "5123796  9000.0  1085    0.136456              0.118550  0.97  \n",
            "5123797  9200.0  1085    0.136456              0.118550  0.97  \n",
            "\n",
            "[5123798 rows x 10 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 5123798 entries, 0 to 5123797\n",
            "Data columns (total 10 columns):\n",
            " #   Column                Dtype  \n",
            "---  ------                -----  \n",
            " 0   Unnamed: 0            int64  \n",
            " 1   Quote_date            object \n",
            " 2   Expire_date           object \n",
            " 3   Price                 float64\n",
            " 4   Underlying_last       float64\n",
            " 5   Strike                float64\n",
            " 6   Ttl                   int64  \n",
            " 7   Volatility            float64\n",
            " 8   Volatility_GJR_GARCH  float64\n",
            " 9   R                     float64\n",
            "dtypes: float64(6), int64(2), object(2)\n",
            "memory usage: 390.9+ MB\n",
            "         Unnamed: 0  Quote_date Expire_date     Price  Underlying_last  \\\n",
            "0           1354913  2019-01-02  2019-01-04  1707.050          2509.98   \n",
            "1           1354914  2019-01-02  2019-01-04  1607.495          2509.98   \n",
            "2           1354915  2019-01-02  2019-01-04  1507.500          2509.98   \n",
            "3           1354916  2019-01-02  2019-01-04  1458.295          2509.98   \n",
            "4           1354917  2019-01-02  2019-01-04  1408.300          2509.98   \n",
            "...             ...         ...         ...       ...              ...   \n",
            "5123793     6521988  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123794     6521989  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123795     6521990  2021-12-31  2024-12-20   150.900          4766.39   \n",
            "5123796     6521991  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "5123797     6521992  2021-12-31  2024-12-20   150.000          4766.39   \n",
            "\n",
            "         Strike   Ttl  Volatility  Volatility_GJR_GARCH     R  \n",
            "0         800.0     2    0.202726              0.272634  2.40  \n",
            "1         900.0     2    0.202726              0.272634  2.40  \n",
            "2        1000.0     2    0.202726              0.272634  2.40  \n",
            "3        1050.0     2    0.202726              0.272634  2.40  \n",
            "4        1100.0     2    0.202726              0.272634  2.40  \n",
            "...         ...   ...         ...                   ...   ...  \n",
            "5123793  8400.0  1085    0.136456              0.118550  0.97  \n",
            "5123794  8600.0  1085    0.136456              0.118550  0.97  \n",
            "5123795  8800.0  1085    0.136456              0.118550  0.97  \n",
            "5123796  9000.0  1085    0.136456              0.118550  0.97  \n",
            "5123797  9200.0  1085    0.136456              0.118550  0.97  \n",
            "\n",
            "[5123798 rows x 10 columns]\n",
            "1095\n"
          ]
        }
      ],
      "source": [
        "# Load dataset\n",
        "df_read = read_file(\"../data/processed_data/2019-2021_underlying-strike_only-price.csv\")\n",
        "print(df_read)\n",
        "df_read.info()\n",
        "print(df_read)\n",
        "print(df_read[\"Ttl\"].max())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEPU0KkgpQXH",
        "outputId": "7c661fbc-dc98-4008-e030-97997bb01bbe"
      },
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "from dateutil.relativedelta import relativedelta\n",
        "\n",
        "training_period = 10\n",
        "val_period = 1\n",
        "test_period = 1\n",
        "num_models = 12\n",
        "\n",
        "features = [\"Underlying_last\", \"Strike\", \"Ttl\", \"Volatility_GJR_GARCH\", \"R\"]\n",
        "seq_length = 5\n",
        "num_features = len(features)\n",
        "num_outputs = 1\n",
        "\n",
        "df_read_lags = lag_features(df_read, features, seq_length)\n",
        "\n",
        "train_val_test = []\n",
        "\n",
        "month = 4\n",
        "year = 0\n",
        "for i in range(num_models):\n",
        "    if month == 13:\n",
        "        year += 1\n",
        "        month = 1\n",
        "    train_start = datetime(2020 + year, month, 1)\n",
        "    val_start = train_start + relativedelta(months=8)\n",
        "    test_start = val_start + relativedelta(months=1)\n",
        "    test_end = test_start + relativedelta(months=1)\n",
        "\n",
        "    month += 1\n",
        "\n",
        "    df_train_orginal = df_read_lags.loc[(df_read_lags.loc[:, \"Quote_date\"] >= str(train_start)) & (df_read_lags.loc[:, \"Quote_date\"] < str(val_start)), :]\n",
        "    df_val_orginal = df_read_lags.loc[(df_read_lags.loc[:, \"Quote_date\"] >= str(val_start)) & (df_read_lags.loc[:, \"Quote_date\"] < str(test_start)), :]\n",
        "    df_test_orginal = df_read_lags.loc[(df_read_lags.loc[:, \"Quote_date\"] >= str(test_start)) & (df_read_lags.loc[:, \"Quote_date\"] < str(test_end)), :]\n",
        "\n",
        "    train_x_org, train_y_org = df_to_xy(df_train_orginal)\n",
        "    val_x_org, val_y_org = df_to_xy(df_val_orginal)\n",
        "    test_x_org, test_y_org = df_to_xy(df_test_orginal)\n",
        "\n",
        "    scaler = MinMaxScaler()\n",
        "    train_x_scaled = scaler.fit_transform(train_x_org)\n",
        "    val_x_scaled = scaler.transform(val_x_org)\n",
        "    test_x_scaled = scaler.transform(test_x_org)\n",
        "\n",
        "    \"\"\"shuffle = np.random.permutation(len(train_x_scaled))\n",
        "    train_x_scaled, train_y_scaled = train_x_scaled[shuffle], train_y_scaled[shuffle]\"\"\"\n",
        "\n",
        "    train_x_scaled = np.reshape(train_x_scaled, (len(train_x_scaled), num_features))\n",
        "    val_x_scaled = np.reshape(val_x_scaled, (len(val_x_scaled), num_features))\n",
        "    test_x_scaled = np.reshape(test_x_scaled, (len(test_x_scaled), num_features))\n",
        "\n",
        "    # print(f\"Train_x shape: {train_x_scaled.shape}, train_y shape: {train_y_org.shape}\")\n",
        "    # print(f\"Test_x shape: {test_x_scaled.shape}, test_y shape: {test_y_org.shape}\")\n",
        "    # print(\"------------------------------------------------\")\n",
        "    train_val_test.append(((train_x_scaled, train_y_org), (val_x_scaled, val_y_org), (test_x_scaled, test_y_org)))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 738
        },
        "id": "5ai3RgkWpVA3",
        "outputId": "a5f563c2-18c3-4626-c7b7-6fc747bc467e"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Input, Dropout, BatchNormalization\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.optimizers import AdamW\n",
        "import keras as KER\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.activations import linear, relu\n",
        "from datetime import datetime\n",
        "from tensorflow.keras.metrics import MeanSquaredError, RootMeanSquaredError"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "wtvth-7Vz87q"
      },
      "outputs": [],
      "source": [
        "def create_model(config):\n",
        "  \"\"\"Builds a model of minimum 2 layers sequentially from a given config dictionary\"\"\"\n",
        "  model = Sequential()\n",
        "\n",
        "  model.add(Dense(\n",
        "    units = config[\"units\"],\n",
        "    activation = relu,\n",
        "    input_shape = (config[\"num_features\"],)\n",
        "  ))\n",
        "\n",
        "  model.add(BatchNormalization(\n",
        "    momentum = config[\"bn_momentum\"]\n",
        "  ))\n",
        "\n",
        "\n",
        "  for i in range(config[\"layers\"]-2):\n",
        "    model.add(Dense(\n",
        "      units = config[\"units\"],\n",
        "      activation = relu\n",
        "    ))\n",
        "    model.add(BatchNormalization(\n",
        "      momentum = config[\"bn_momentum\"]\n",
        "    ))\n",
        "\n",
        "  model.add(Dense(\n",
        "    units = config[\"units\"],\n",
        "    activation = relu\n",
        "  ))\n",
        "\n",
        "  model.add(BatchNormalization(\n",
        "    momentum = config[\"bn_momentum\"]\n",
        "  ))\n",
        "\n",
        "  model.add(Dense(\n",
        "    units = num_outputs,\n",
        "    activation = relu\n",
        "  ))  \n",
        "\n",
        "  model.compile(\n",
        "    optimizer = AdamW(\n",
        "      learning_rate = config[\"learning_rate\"],\n",
        "      weight_decay = config[\"weight_decay\"]\n",
        "    ),\n",
        "    loss = \"mse\",\n",
        "  )\n",
        "\n",
        "  return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zMFVcYRHpWNo",
        "outputId": "158d9438-08de-4d33-9f64-3bc2f2460ee3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_32\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_32\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_224 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">576</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_192         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_225 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_193         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_226 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_194         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_227 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_195         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_228 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_196         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_229 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,312</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_197         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_230 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">97</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_224 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m576\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_192         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_225 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m9,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_193         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_226 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m9,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_194         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_227 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m9,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_195         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_228 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m9,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_196         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_229 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │         \u001b[38;5;34m9,312\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ batch_normalization_197         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)             │           \u001b[38;5;34m384\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_230 (\u001b[38;5;33mDense\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m97\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">49,537</span> (193.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m49,537\u001b[0m (193.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">48,385</span> (189.00 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m48,385\u001b[0m (189.00 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,152</span> (4.50 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,152\u001b[0m (4.50 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 8ms/step - loss: 781317.6875 - val_loss: 2645.0242\n",
            "Epoch 2/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 1869.5724 - val_loss: 2582.5642\n",
            "Epoch 3/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 981.2454 - val_loss: 2540.4434\n",
            "Epoch 4/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 924.7442 - val_loss: 2356.3928\n",
            "Epoch 5/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 895.4520 - val_loss: 2271.3467\n",
            "Epoch 6/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 890.8079 - val_loss: 2277.8105\n",
            "Epoch 7/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 881.9214 - val_loss: 1761.8035\n",
            "Epoch 8/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 868.7173 - val_loss: 1431.4600\n",
            "Epoch 9/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 862.4777 - val_loss: 1205.6292\n",
            "Epoch 10/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 851.9620 - val_loss: 1078.9939\n",
            "Epoch 11/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 841.3065 - val_loss: 1118.4469\n",
            "Epoch 12/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 841.9966 - val_loss: 946.9839\n",
            "Epoch 13/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 816.6540 - val_loss: 932.6559\n",
            "Epoch 14/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 8ms/step - loss: 805.6061 - val_loss: 971.4178\n",
            "Epoch 15/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 798.2497 - val_loss: 1000.8891\n",
            "Epoch 16/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 793.6704 - val_loss: 1044.5374\n",
            "Epoch 17/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 789.1787 - val_loss: 1069.2959\n",
            "Epoch 18/100\n",
            "\u001b[1m585/585\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 9ms/step - loss: 785.7529 - val_loss: 1048.7848\n",
            "Test loss: 832.2062\n"
          ]
        }
      ],
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "import tensorflow as tf\n",
        "\n",
        "config = {\n",
        "    \"units\": 96,\n",
        "    \"learning_rate\": 0.004102449498283615,\n",
        "    \"layers\": 6,\n",
        "    \"seq_length\": seq_length,\n",
        "    \"num_features\": num_features,\n",
        "    \"bn_momentum\" : 0.32753376728017486,\n",
        "    \"weight_decay\" : 0.0002017422068564576\n",
        "}\n",
        "\n",
        "def trainer(train_x, train_y, model, val_x, val_y):\n",
        "    epochs = 100\n",
        "    minibatch_size = 2048\n",
        "\n",
        "    tf.random.set_seed(5)\n",
        "\n",
        "    early_stopping = EarlyStopping(\n",
        "        monitor='val_loss',\n",
        "        mode='min',\n",
        "        min_delta = 1,\n",
        "        patience = 5,\n",
        "    )\n",
        "\n",
        "    model.fit(\n",
        "        train_x,\n",
        "        train_y,\n",
        "        batch_size = minibatch_size,\n",
        "        validation_data = (val_x, val_y),\n",
        "        epochs = epochs,\n",
        "        callbacks = [early_stopping]\n",
        "    )\n",
        "\n",
        "predictions = []\n",
        "for i, ((x_train, y_train), (x_val, y_val), (x_test, y_test)) in enumerate(train_val_test):\n",
        "    if i == 9:\n",
        "        model = create_model(config)\n",
        "        model.summary()\n",
        "        trainer(x_train, y_train, model, x_val, y_val)\n",
        "\n",
        "        pred = np.array(model(x_test)).flatten()\n",
        "        print(\"Test loss:\", np.mean((pred-y_test)**2))\n",
        "        \n",
        "        predictions.append(np.array(model(x_test)))\n",
        "\n",
        "# predictions = np.array(predictions)\n",
        "predictions = np.concatenate(predictions)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "17p20nE8yLxu",
        "outputId": "13a90785-3b58-44e8-c054-762cb82a60ba"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/var/folders/3t/5vvh8l5x48s7tyvbx4b6v9xr0000gn/T/ipykernel_14098/238341932.py:3: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  df_test[\"Prediction\"] = predictions\n"
          ]
        }
      ],
      "source": [
        "def prediction(df_test, predictions):\n",
        "    # df_test[\"Prediction\"] = predictions.flatten()\n",
        "    df_test[\"Prediction\"] = predictions\n",
        "\n",
        "    # m = MeanSquaredError()\n",
        "    # m.update_state(test_y_org, predictions)\n",
        "    # print(\"MSE from model:\", m.result().numpy())\n",
        "    # m = RootMeanSquaredError()\n",
        "    # m.update_state(test_y_org, predictions)\n",
        "    # print(\"RMSE from model:\", m.result().numpy())\n",
        "\n",
        "    return df_test\n",
        "\n",
        "df_test_whole = df_read_lags.loc[df_read_lags.loc[:, \"Quote_date\"] >= \"2021-01-01\", :]\n",
        "df_test_whole = prediction(df_test_whole, predictions)\n",
        "\n",
        "#print(train_y_org[:, :1].min(), train_y_org[:, :1].max())\n",
        "#print(train_y_org[:, 1:].min(), train_y_org[:, 1:].max())\n",
        "\n",
        "from pathlib import Path\n",
        "from datetime import datetime\n",
        "\n",
        "time = datetime.now()\n",
        "time = time.strftime(\"%m-%d_%H-%M\")\n",
        "\n",
        "filename = f\"../data/Predictions/{last_year}_predictions_{time}_GARCH.csv\"\n",
        "filepath = Path(filename)\n",
        "filepath.parent.mkdir(parents=True, exist_ok = True)\n",
        "df_test_whole.to_csv(filename)\n",
        "#df_test.info()\n",
        "#print(df_test.head())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1845482 entries, 0 to 1845481\n",
            "Data columns (total 39 columns):\n",
            " #   Column                  Dtype  \n",
            "---  ------                  -----  \n",
            " 0   Unnamed: 0.2            int64  \n",
            " 1   Unnamed: 0.1            int64  \n",
            " 2   Unnamed: 0              int64  \n",
            " 3   Quote_date              object \n",
            " 4   Expire_date             object \n",
            " 5   Price                   float64\n",
            " 6   Underlying_last         float64\n",
            " 7   Strike                  float64\n",
            " 8   Ttl                     int64  \n",
            " 9   Volatility              float64\n",
            " 10  Volatility_GJR_GARCH    float64\n",
            " 11  R                       float64\n",
            " 12  Underlying_last-4       float64\n",
            " 13  Strike-4                float64\n",
            " 14  Ttl-4                   float64\n",
            " 15  Volatility_GJR_GARCH-4  float64\n",
            " 16  R-4                     float64\n",
            " 17  Underlying_last-3       float64\n",
            " 18  Strike-3                float64\n",
            " 19  Ttl-3                   float64\n",
            " 20  Volatility_GJR_GARCH-3  float64\n",
            " 21  R-3                     float64\n",
            " 22  Underlying_last-2       float64\n",
            " 23  Strike-2                float64\n",
            " 24  Ttl-2                   float64\n",
            " 25  Volatility_GJR_GARCH-2  float64\n",
            " 26  R-2                     float64\n",
            " 27  Underlying_last-1       float64\n",
            " 28  Strike-1                float64\n",
            " 29  Ttl-1                   float64\n",
            " 30  Volatility_GJR_GARCH-1  float64\n",
            " 31  R-1                     float64\n",
            " 32  Underlying_last-0       float64\n",
            " 33  Strike-0                float64\n",
            " 34  Ttl-0                   int64  \n",
            " 35  Volatility_GJR_GARCH-0  float64\n",
            " 36  R-0                     float64\n",
            " 37  Price_last              float64\n",
            " 38  Prediction              float64\n",
            "dtypes: float64(32), int64(5), object(2)\n",
            "memory usage: 549.1+ MB\n",
            "   Unnamed: 0.2  Unnamed: 0.1  Unnamed: 0  Quote_date Expire_date     Price  \\\n",
            "0             0       3102998     4482920  2021-01-04  2021-05-28   919.600   \n",
            "1             1       3103091     4483013  2021-01-04  2021-05-28    69.045   \n",
            "2             2       3104380     4484302  2021-01-04  2022-03-18  1310.100   \n",
            "3             3       3104484     4484406  2021-01-04  2022-06-17  2143.910   \n",
            "4             4       3097922     4477844  2021-01-04  2021-01-06    84.595   \n",
            "\n",
            "   Underlying_last  Strike  Ttl  Volatility  ...  Ttl-1  \\\n",
            "0          3701.38  2800.0  144    0.185353  ...  148.0   \n",
            "1          3701.38  3950.0  144    0.185353  ...  148.0   \n",
            "2          3701.38  2400.0  438    0.185353  ...  442.0   \n",
            "3          3701.38  1500.0  529    0.185353  ...  533.0   \n",
            "4          3701.38  3625.0    2    0.185353  ...    6.0   \n",
            "\n",
            "   Volatility_GJR_GARCH-1   R-1  Underlying_last-0  Strike-0  Ttl-0  \\\n",
            "0                0.091438  0.09            3701.38    2800.0    144   \n",
            "1                0.091438  0.09            3701.38    3950.0    144   \n",
            "2                0.091438  0.10            3701.38    2400.0    438   \n",
            "3                0.091438  0.10            3701.38    1500.0    529   \n",
            "4                0.091438  0.08            3701.38    3625.0      2   \n",
            "\n",
            "   Volatility_GJR_GARCH-0   R-0  Price_last   Prediction  \n",
            "0                0.088931  0.09     919.600   926.975460  \n",
            "1                0.088931  0.09      69.045    60.661617  \n",
            "2                0.088931  0.10    1310.100  1317.590300  \n",
            "3                0.088931  0.10    2143.910  2158.544000  \n",
            "4                0.088931  0.09      84.595    45.181858  \n",
            "\n",
            "[5 rows x 39 columns]\n"
          ]
        }
      ],
      "source": [
        "# Run this if one month is very bad\n",
        "\n",
        "if True:\n",
        "    df_test_whole = pd.read_csv(\"../data/Predictions/2021_predictions_09-30_14-42_GARCH.csv\")\n",
        "    df_test_whole.loc[(df_test_whole.loc[:, \"Quote_date\"] >= \"2021-10-01 00:00:00\") & (df_test_whole.loc[:, \"Quote_date\"] < \"2021-11-01 00:00:00\"), \"Prediction\"] = predictions\n",
        "\n",
        "    from datetime import datetime\n",
        "    time = datetime.now()\n",
        "    time = time.strftime(\"%m-%d_%H-%M\")\n",
        "\n",
        "    filename = f\"../data/Predictions/{last_year}_predictions_{time}_GARCH.csv\"\n",
        "    filepath = Path(filename)\n",
        "    filepath.parent.mkdir(parents=True, exist_ok = True)\n",
        "    df_test_whole.to_csv(filename)\n",
        "\n",
        "    df_test_whole.info()\n",
        "    print(df_test_whole.head())"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.8.1 ('A_Star-bay7YQ3K')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "vscode": {
      "interpreter": {
        "hash": "346f1978fc3949933b17c75d4815baa97117852380bde1b98c856e676f6b5766"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
